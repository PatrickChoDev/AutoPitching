{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.rand(4, 400, 256).to(device)  # batch, num_frames, feature_dim\n",
    "lengths = torch.randint(1, 200, (4,)).to(device)  # batch\n",
    "output, lengths = emformer(input, lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.0751,  1.1741,  0.2803,  ..., -1.3751,  1.7454,  2.6569],\n",
      "         [ 0.4204,  1.7470,  0.2313,  ...,  0.1595,  1.5232, -0.7971],\n",
      "         [ 1.3585, -0.3609,  0.6504,  ...,  1.2292,  1.7976, -1.1870],\n",
      "         ...,\n",
      "         [-0.6052, -0.3736,  1.1656,  ..., -0.2788, -1.1069, -0.5875],\n",
      "         [-0.8173, -0.7149,  2.1800,  ..., -1.6249,  0.0324,  0.7269],\n",
      "         [-0.2114, -0.6623,  0.5437,  ..., -0.4885,  1.0311, -1.4219]],\n",
      "\n",
      "        [[-0.7416,  0.5183, -1.5463,  ...,  0.4775, -0.0608, -0.4215],\n",
      "         [-0.8543, -1.1387,  0.3019,  ..., -0.0884,  1.5694,  0.9932],\n",
      "         [-0.6936,  1.1782,  0.2838,  ..., -0.9359,  0.6605, -0.2664],\n",
      "         ...,\n",
      "         [ 0.2511, -0.6351,  0.8071,  ...,  0.9944,  1.4654,  0.7430],\n",
      "         [-0.0368, -0.9818,  0.4863,  ...,  0.9570,  0.6864, -0.0708],\n",
      "         [ 0.1201, -0.2853,  0.3010,  ..., -0.1932,  1.6423,  0.1028]],\n",
      "\n",
      "        [[-0.9769, -0.6440,  2.0863,  ..., -0.6719, -0.7626,  0.9121],\n",
      "         [-1.7482,  0.5123, -0.0846,  ..., -0.0750, -0.1944, -0.3631],\n",
      "         [ 0.1078,  0.9354, -0.2366,  ..., -1.5346, -0.3700,  0.1656],\n",
      "         ...,\n",
      "         [ 0.3640,  2.4522,  0.5856,  ..., -0.3589, -0.2371, -1.7566],\n",
      "         [-0.0475,  1.8175,  0.7947,  ..., -0.6595,  0.8625, -1.1628],\n",
      "         [-0.1270,  2.2937,  1.1063,  ...,  0.0145,  0.3601, -0.8158]],\n",
      "\n",
      "        [[-1.1669, -0.3806, -0.6970,  ..., -0.6175,  1.7892, -1.1842],\n",
      "         [-1.0686,  0.2629,  0.5871,  ..., -0.7768,  1.1882, -1.1786],\n",
      "         [-1.0485,  0.8934, -0.5647,  ..., -0.7509,  0.9867,  0.2698],\n",
      "         ...,\n",
      "         [-2.6863,  1.1426, -1.8270,  ..., -3.3292,  0.7367,  0.1235],\n",
      "         [-2.7361,  0.0144, -0.7673,  ..., -3.2258,  1.2270,  0.0590],\n",
      "         [-2.7810,  0.1394, -1.2454,  ..., -3.4198,  0.3666,  0.3189]]],\n",
      "       device='cuda:0', grad_fn=<PermuteBackward0>) tensor([116, 107,  52,   2], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(output,lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "del output,lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eslasped 0.01201772689819336\n"
     ]
    }
   ],
   "source": [
    "input = torch.rand(1, 9, 256)\n",
    "lengths = torch.ones(1) * 9\n",
    "start = time.time()\n",
    "output, lengths, states = emformer.infer(input.to(device), lengths.to(device),None)\n",
    "end = time.time()\n",
    "print('Eslasped',end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 256])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(emformer.children())[0].kernel_size[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "from torchaudio.pipelines import EMFORMER_RNNT_BASE_LIBRISPEECH\n",
    "import torch\n",
    "# Non-streaming inference.\n",
    "# Build feature extractor, decoder with RNN-T model, and token processor.\n",
    "feature_extractor = EMFORMER_RNNT_BASE_LIBRISPEECH.get_feature_extractor()\n",
    "decoder = EMFORMER_RNNT_BASE_LIBRISPEECH.get_decoder()\n",
    "Downloading: \"https://download.pytorch.org/torchaudio/models/emformer_rnnt_base_librispeech.pt\"\n",
    "token_processor = EMFORMER_RNNT_BASE_LIBRISPEECH.get_token_processor()\n",
    "# Instantiate LibriSpeech dataset; retrieve waveform for first sample.\n",
    "dataset = torchaudio.datasets.LIBRISPEECH(\"./data/librespeech\", url=\"test-clean\",download=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNNTBeamSearch(\n",
       "  (model): RNNT(\n",
       "    (transcriber): _EmformerEncoder(\n",
       "      (input_linear): Linear(in_features=80, out_features=128, bias=False)\n",
       "      (time_reduction): _TimeReduction()\n",
       "      (transformer): Emformer(\n",
       "        (memory_op): AvgPool1d(kernel_size=(4,), stride=(4,), padding=(0,))\n",
       "        (emformer_layers): ModuleList(\n",
       "          (0-19): 20 x _EmformerLayer(\n",
       "            (attention): _EmformerAttention(\n",
       "              (emb_to_key_value): Linear(in_features=512, out_features=1024, bias=True)\n",
       "              (emb_to_query): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            )\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (memory_op): AvgPool1d(kernel_size=(4,), stride=(4,), padding=(0,))\n",
       "            (pos_ff): Sequential(\n",
       "              (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (2): GELU(approximate='none')\n",
       "              (3): Dropout(p=0.1, inplace=False)\n",
       "              (4): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              (5): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm_input): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (layer_norm_output): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (output_linear): Linear(in_features=512, out_features=1024, bias=True)\n",
       "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (predictor): _Predictor(\n",
       "      (embedding): Embedding(4097, 512)\n",
       "      (input_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (lstm_layers): ModuleList(\n",
       "        (0-2): 3 x _CustomLSTM(\n",
       "          (x2g): Linear(in_features=512, out_features=2048, bias=False)\n",
       "          (p2g): Linear(in_features=512, out_features=2048, bias=False)\n",
       "          (c_norm): LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "          (g_norm): LayerNorm((2048,), eps=0.001, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "      (linear): Linear(in_features=512, out_features=1024, bias=True)\n",
       "      (output_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (joiner): _Joiner(\n",
       "      (linear): Linear(in_features=1024, out_features=4097, bias=True)\n",
       "      (activation): ReLU()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "decoder.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he hoped there would be stew for dinner turnips and carrots and bruised potatoes and fat mutton pieces to be ladled out in thick peppered flour fat and sauce tensor([[-0.0557, -0.0557, -1.1367,  ..., -1.1762, -1.2420, -1.0377],\n",
      "        [-0.1895, -0.1893, -0.2915,  ..., -0.7555, -0.7314, -0.7503],\n",
      "        [-0.2962, -0.2958, -0.3840,  ..., -0.8993, -0.6641, -0.6368],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]])\n"
     ]
    }
   ],
   "source": [
    "waveform = next(iter(dataset))[0].squeeze()\n",
    "with torch.no_grad():\n",
    "    # Produce mel-scale spectrogram features.\n",
    "    features, length = feature_extractor(waveform)\n",
    "    # Generate top-10 hypotheses.\n",
    "    hypotheses = decoder(features, length, 10)\n",
    "# For top hypothesis, convert predicted tokens to text.\n",
    "text = token_processor(hypotheses[0][0])\n",
    "print(text,features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([166960])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "waveform.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1048, 80]) tensor([1048])\n"
     ]
    }
   ],
   "source": [
    "print(features.shape,length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torchaudio.pipelines.rnnt_pipeline._SentencePieceTokenProcessor at 0x7f8d883f2cd0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class RawHead(nn.Module):\n",
    "    def __init__(self, hidden_size, num_layers, class_num=1, dropout=0.01):\n",
    "        super().__init__()\n",
    "        self.ff_dropout = dropout\n",
    "        self.hidden_size = hidden_size\n",
    "        self.feat = nn.Sequential(\n",
    "            *[\n",
    "                self._make_layer(hidden_size, hidden_size)\n",
    "                for _ in range(num_layers - 1)\n",
    "            ],\n",
    "            nn.Linear(hidden_size, hidden_size)\n",
    "        )\n",
    "        self.head = nn.Sequential(\n",
    "            nn.LayerNorm(self.hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(self.ff_dropout),\n",
    "            nn.Linear(hidden_size, class_num),\n",
    "        )\n",
    "\n",
    "    def _make_layer(self, input_size, output_size):\n",
    "        return nn.Sequential(\n",
    "            nn.Linear(input_size, output_size),\n",
    "            nn.LayerNorm(self.hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(self.ff_dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        out = self.feat(inputs)\n",
    "        conf = self.head(out)\n",
    "        return out,conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RawHead(\n",
       "  (feat): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Linear(in_features=80, out_features=80, bias=True)\n",
       "      (1): LayerNorm((80,), eps=1e-05, elementwise_affine=True)\n",
       "      (2): ReLU()\n",
       "      (3): Dropout(p=0.01, inplace=False)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Linear(in_features=80, out_features=80, bias=True)\n",
       "      (1): LayerNorm((80,), eps=1e-05, elementwise_affine=True)\n",
       "      (2): ReLU()\n",
       "      (3): Dropout(p=0.01, inplace=False)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Linear(in_features=80, out_features=80, bias=True)\n",
       "      (1): LayerNorm((80,), eps=1e-05, elementwise_affine=True)\n",
       "      (2): ReLU()\n",
       "      (3): Dropout(p=0.01, inplace=False)\n",
       "    )\n",
       "    (3): Linear(in_features=80, out_features=80, bias=True)\n",
       "  )\n",
       "  (head): Sequential(\n",
       "    (0): LayerNorm((80,), eps=1e-05, elementwise_affine=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.01, inplace=False)\n",
       "    (3): Linear(in_features=80, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head = RawHead(80,4,1)\n",
    "head.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "\n",
      "3.3725433349609375\n",
      "tensor(0.4382, grad_fn=<MedianBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "inp = torch.rand(2048,80)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "features.to(device)\n",
    "print(features.device)\n",
    "start = time.time()\n",
    "feat,conf = head(features)\n",
    "hypotheses = decoder(feat.to(device), length, 10)\n",
    "end = time.time()\n",
    "print(feat.shape)\n",
    "print(token_processor(hypotheses[0][0]))\n",
    "print(end-start)\n",
    "print(conf.sigmoid().median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"Trains a SentencePiece model on transcripts across LibriSpeech train-clean-100, train-clean-360, and train-other-500.\n",
    "\n",
    "Example:\n",
    "python train_spm.py --librispeech-path ./datasets\n",
    "\"\"\"\n",
    "\n",
    "import io\n",
    "import pathlib\n",
    "from argparse import ArgumentParser, RawTextHelpFormatter\n",
    "\n",
    "import sentencepiece as spm\n",
    "\n",
    "\n",
    "def get_transcript_text(transcript_path):\n",
    "    with open(transcript_path) as f:\n",
    "        return [line.strip().split(\" \", 1)[1].lower() for line in f]\n",
    "\n",
    "\n",
    "def get_transcripts(dataset_path):\n",
    "    transcript_paths = dataset_path.glob(\"*/*/*.trans.txt\")\n",
    "    merged_transcripts = []\n",
    "    for path in transcript_paths:\n",
    "        merged_transcripts += get_transcript_text(path)\n",
    "    return merged_transcripts\n",
    "\n",
    "\n",
    "def train_spm(input):\n",
    "    model_writer = io.BytesIO()\n",
    "    spm.SentencePieceTrainer.train(\n",
    "        sentence_iterator=iter(input),\n",
    "        model_writer=model_writer,\n",
    "        vocab_size=90,\n",
    "        model_type=\"bpe\",\n",
    "        input_sentence_size=-1,\n",
    "        character_coverage=1.0,\n",
    "        bos_id=0,\n",
    "        pad_id=1,\n",
    "        eos_id=2,\n",
    "        unk_id=3,\n",
    "    )\n",
    "    return model_writer.getvalue()\n",
    "\n",
    "\n",
    "def parse_args():\n",
    "    parser = ArgumentParser(description=__doc__, formatter_class=RawTextHelpFormatter)\n",
    "    parser.add_argument(\n",
    "        \"--librispeech-path\",\n",
    "        required=True,\n",
    "        type=pathlib.Path,\n",
    "        help=\"Path to LibriSpeech dataset.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--output-file\",\n",
    "        default=pathlib.Path(\"./spm_bpe_4096.model\"),\n",
    "        type=pathlib.Path,\n",
    "        help=\"File to save model to. (Default: './spm_bpe_4096.model')\",\n",
    "    )\n",
    "    return parser.parse_args()\n",
    "\n",
    "\n",
    "def run_cli():\n",
    "    args = parse_args()\n",
    "\n",
    "    root = args.librispeech_path / \"LibriSpeech\"\n",
    "    splits = [\"train-clean-100\", \"train-clean-360\", \"train-other-500\"]\n",
    "    merged_transcripts = []\n",
    "    for split in splits:\n",
    "        path = pathlib.Path(root) / split\n",
    "        merged_transcripts += get_transcripts(path)\n",
    "\n",
    "    model = train_spm(merged_transcripts)\n",
    "\n",
    "    with open(args.output_file, \"wb\") as f:\n",
    "        f.write(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input_format: \n",
      "  model_prefix: \n",
      "  model_type: BPE\n",
      "  vocab_size: 90\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 1\n",
      "  input_sentence_size: 18446744073709551615\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  pretokenization_delimiter: \n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 3\n",
      "  bos_id: 0\n",
      "  eos_id: 2\n",
      "  pad_id: 1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "  enable_differential_privacy: 0\n",
      "  differential_privacy_noise_level: 0\n",
      "  differential_privacy_clipping_threshold: 0\n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(407) LOG(INFO) Loaded all 4 sentences\n",
      "trainer_interface.cc(423) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(423) LOG(INFO) Adding meta_piece: <pad>\n",
      "trainer_interface.cc(423) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(423) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(428) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(537) LOG(INFO) all chars count=40\n",
      "trainer_interface.cc(558) LOG(INFO) Alphabet size=19\n",
      "trainer_interface.cc(559) LOG(INFO) Final character coverage=1\n",
      "trainer_interface.cc(591) LOG(INFO) Done! preprocessed 4 sentences.\n",
      "trainer_interface.cc(597) LOG(INFO) Tokenizing input sentences with whitespace: 4\n",
      "trainer_interface.cc(608) LOG(INFO) Done! 4\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=3 min_freq=1\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=20 all=63 active=44 piece=▁ว่าไ\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=0 size=40 all=47 active=28 piece=่า\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=0 size=60 all=27 active=8 piece=ีครับ\n"
     ]
    }
   ],
   "source": [
    "mdoel = train_spm(['สวัสดีครับ','เฮ้ย','ว่าไงหรอครับ','สบายดีครับ'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
